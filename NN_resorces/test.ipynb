{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import pad\n",
    "from Dataset import Dataset, Dataset_warped\n",
    "from Example import FeatureExtraction, ProcessImage, Model\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 1\n",
    "EPOCHS = 1\n",
    "LR = 1\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "featExtrac = FeatureExtraction(3).to(device)\n",
    "model = Model().to(device)\n",
    "level1 = ProcessImage(96,3).to(device)\n",
    "level2 = ProcessImage(192,64).to(device)\n",
    "level3 = ProcessImage(384,128).to(device)\n",
    "level4 = ProcessImage(512,256).to(device)\n",
    "dir_dataset = '../dataset2'\n",
    "dataset = Dataset(dir = dir_dataset, transform=transforms.ToTensor())\n",
    "optimizer1 = optim.Adam(level1.parameters(), lr=LR)\n",
    "optimizer2 = optim.Adam(level2.parameters(), lr=LR)\n",
    "optimizer3 = optim.Adam(level3.parameters(), lr=LR)\n",
    "optimizer4 = optim.Adam(level4.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = dataset.__len__()\n",
    "test = length//10\n",
    "train = length - test\n",
    "trainset, testset = random_split(dataset,[train,test])\n",
    "trainset = DataLoader(trainset, batch_size=BATCH, shuffle=True, pin_memory=True,num_workers=2)\n",
    "testset = DataLoader(testset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m loss2  \u001b[39m=\u001b[39m lossFunction2(out2 , features2[\u001b[39m1\u001b[39m])\n\u001b[0;32m     29\u001b[0m loss1  \u001b[39m=\u001b[39m lossFunction1(out1 , F2\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m---> 30\u001b[0m loss4\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     31\u001b[0m loss3\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     32\u001b[0m loss2\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Mau\\anaconda3\\envs\\proyecto-final\\Lib\\site-packages\\torch\\_tensor.py:428\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[39m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_tensor_str\u001b[39m.\u001b[39m_str(\u001b[39mself\u001b[39m, tensor_contents\u001b[39m=\u001b[39mtensor_contents)\n\u001b[1;32m--> 428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(\n\u001b[0;32m    429\u001b[0m     \u001b[39mself\u001b[39m, gradient\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, retain_graph\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, create_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, inputs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    430\u001b[0m ):\n\u001b[0;32m    431\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[0;32m    433\u001b[0m \u001b[39m    The graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[39m            used to compute the attr::tensors.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    477\u001b[0m     \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lossFunction1 = torch.nn.SmoothL1Loss()\n",
    "lossFunction2 = torch.nn.SmoothL1Loss()\n",
    "lossFunction3 = torch.nn.SmoothL1Loss()\n",
    "lossFunction4 = torch.nn.SmoothL1Loss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        (F1,F2,F3) = data \n",
    "        b,c,h,w = F1.shape\n",
    "        if h%8>0 or w%8>0:\n",
    "            F1 = pad(F1, (0,0,h%8,w%8), \"constant\", 0)\n",
    "            F2 = pad(F2, (0,0,h%8,w%8), \"constant\", 0)\n",
    "            F3 = pad(F3, (0,0,h%8,w%8), \"constant\", 0)\n",
    "        with torch.no_grad():\n",
    "            features1 = featExtrac(F1.to(device))\n",
    "            features2 = featExtrac(F2.to(device))\n",
    "            features3 = featExtrac(F3.to(device))\n",
    "        input1= torch.cat([features1[0].to(device), features3[0].to(device)], dim=1)\n",
    "        input2= torch.cat([features1[1].to(device), features3[1].to(device)], dim=1)\n",
    "        input3= torch.cat([features1[2].to(device), features3[2].to(device)], dim=1)\n",
    "        input4= torch.cat([features1[3].to(device), features3[3].to(device)], dim=1)\n",
    "        out4, up4 = level4(input4)\n",
    "        out3, up3 = level3(torch.cat([input3, up4], dim=1))\n",
    "        out2, up2 = level2(torch.cat([input2, up3], dim=1))\n",
    "        out1, up1 = level1(torch.cat([input1, up2], dim=1))\n",
    "        loss4  = lossFunction4(out4 , features2[3])\n",
    "        loss3  = lossFunction3(out3 , features2[2])\n",
    "        loss2  = lossFunction2(out2 , features2[1])\n",
    "        loss1  = lossFunction1(out1 , F2.to(device))\n",
    "        loss4.backward()\n",
    "        loss3.backward()\n",
    "        loss2.backward()\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.step()\n",
    "        optimizer2.zero_grad()\n",
    "        optimizer3.step()\n",
    "        optimizer3.zero_grad()\n",
    "        optimizer4.step()\n",
    "        optimizer4.zero_grad()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(testset))\n",
    "(F1,F2,F3) = data\n",
    "with torch.no_grad():\n",
    "    output = model(F1.to(device), F3.to(device))\n",
    "img1 = F1.numpy()[0].transpose(1,2,0)\n",
    "img2 = F2.cpu().numpy()[0].transpose(1,2,0)\n",
    "img3 = F3.numpy()[0].transpose(1,2,0)\n",
    "generated = output.cpu().detach().numpy()[0].transpose(1,2,0)\n",
    "del output, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fNew = cv2.cvtColor(generated, cv2.COLOR_BGR2RGB)\n",
    "f1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "f2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "f3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "fig.add_subplot(2, 2, 1) \n",
    "plt.imshow(f1)\n",
    "plt.title(\"First\")\n",
    "fig.add_subplot(2, 2, 2)\n",
    "plt.imshow(f2)\n",
    "plt.title(\"Second\")\n",
    "fig.add_subplot(2, 2, 3)\n",
    "plt.imshow(f3)\n",
    "plt.title(\"Third\")\n",
    "fig.add_subplot(2, 2, 4)\n",
    "plt.imshow(fNew)\n",
    "plt.title(\"generated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proyecto_Final.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
